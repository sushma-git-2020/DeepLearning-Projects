{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "2-HWFashion_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7xu-gU6X1n9",
        "colab_type": "text"
      },
      "source": [
        "## Fashion-MNIST Dataset (from Kaggle)\n",
        "\n",
        "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n",
        "\n",
        "Zalando seeks to replace the original MNIST dataset\n",
        "\n",
        "Content\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
        "\n",
        "- To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n",
        "- For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB_6D5XnX1oD",
        "colab_type": "text"
      },
      "source": [
        "### 1. Import the dataset \n",
        "\n",
        "Import the dataset `fashiom_mnist` from `keras.datasets`. Check the shape of the train and test datasets. Print couple of images to see how the samples from the dataset look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cokS1eHiX1oK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf4WSsYxYIJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load (downloaded if needed) the fashiom_mnist dataset \n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-VxMgRvYb9l",
        "colab_type": "code",
        "outputId": "61d762a1-8d61-473c-dfce-3ab10451b4f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[500], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[100], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAxVo0yDbN_f",
        "colab_type": "code",
        "outputId": "7c802df0-64d1-453e-e2d7-e3d47c161118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA63LjhUawX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWz6F1_xbT4i",
        "colab_type": "code",
        "outputId": "620b4a58-7dab-432d-a39d-d071a596fb67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zD9wNMebkn1",
        "colab_type": "code",
        "outputId": "be8e33b7-308d-47e1-f076-0c7706e11300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaBjT6ujX1oc",
        "colab_type": "text"
      },
      "source": [
        "### 2. Scale the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w92warCZSU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # normalize inputs from 0-255 to 0-1\n",
        "# X_train = X_train / 255\n",
        "# X_test = X_test / 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hide_input": true,
        "id": "akuJLJrM9ITR",
        "colab": {}
      },
      "source": [
        "mean = np.mean(X_train)\n",
        "stddev = np.std(X_train)\n",
        "\n",
        "X_train = (X_train - mean) / stddev\n",
        "X_test = (X_test - mean) / stddev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlHpoSQmX1oe",
        "colab_type": "text"
      },
      "source": [
        "### 3. Reshape the datasets and implement one-hot-encoding on target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk09Gq4id1AN",
        "colab_type": "code",
        "outputId": "9597d312-3f30-4e78-e277-f789e2a2fa1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yg15cBaPd9Iv",
        "colab": {}
      },
      "source": [
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwW0g05UeFeK",
        "colab_type": "code",
        "outputId": "359eca3e-fcd4-49db-980a-07089ba3be8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_test[200]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Tpl_CieHp4",
        "colab_type": "code",
        "outputId": "f3ecf092-bd27-43d9-e0c6-aa7165e8e313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jLp6C3xX1oi",
        "colab_type": "text"
      },
      "source": [
        "### 4. Build the Baseline Model without CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXicH_gXXvjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(num_pixels, input_dim=num_pixels, activation='relu')) \n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOqsv1FAXvjk",
        "colab_type": "code",
        "outputId": "31b2a0af-d3be-4986-e00d-359be71430f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=200,\n",
        "    verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            " - 4s - loss: 0.4539 - accuracy: 0.8364 - val_loss: 0.3938 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            " - 4s - loss: 0.3405 - accuracy: 0.8742 - val_loss: 0.3835 - val_accuracy: 0.8604\n",
            "Epoch 3/100\n",
            " - 4s - loss: 0.3027 - accuracy: 0.8882 - val_loss: 0.3640 - val_accuracy: 0.8676\n",
            "Epoch 4/100\n",
            " - 4s - loss: 0.2758 - accuracy: 0.8983 - val_loss: 0.3522 - val_accuracy: 0.8763\n",
            "Epoch 5/100\n",
            " - 4s - loss: 0.2552 - accuracy: 0.9058 - val_loss: 0.3360 - val_accuracy: 0.8805\n",
            "Epoch 6/100\n",
            " - 4s - loss: 0.2376 - accuracy: 0.9120 - val_loss: 0.3266 - val_accuracy: 0.8833\n",
            "Epoch 7/100\n",
            " - 4s - loss: 0.2272 - accuracy: 0.9154 - val_loss: 0.3374 - val_accuracy: 0.8804\n",
            "Epoch 8/100\n",
            " - 4s - loss: 0.2086 - accuracy: 0.9222 - val_loss: 0.3311 - val_accuracy: 0.8855\n",
            "Epoch 9/100\n",
            " - 4s - loss: 0.2011 - accuracy: 0.9255 - val_loss: 0.3314 - val_accuracy: 0.8870\n",
            "Epoch 10/100\n",
            " - 4s - loss: 0.1910 - accuracy: 0.9284 - val_loss: 0.3329 - val_accuracy: 0.8879\n",
            "Epoch 11/100\n",
            " - 4s - loss: 0.1817 - accuracy: 0.9309 - val_loss: 0.3536 - val_accuracy: 0.8869\n",
            "Epoch 12/100\n",
            " - 4s - loss: 0.1718 - accuracy: 0.9360 - val_loss: 0.3454 - val_accuracy: 0.8892\n",
            "Epoch 13/100\n",
            " - 4s - loss: 0.1618 - accuracy: 0.9398 - val_loss: 0.3505 - val_accuracy: 0.8881\n",
            "Epoch 14/100\n",
            " - 4s - loss: 0.1526 - accuracy: 0.9421 - val_loss: 0.3523 - val_accuracy: 0.8930\n",
            "Epoch 15/100\n",
            " - 4s - loss: 0.1483 - accuracy: 0.9441 - val_loss: 0.3437 - val_accuracy: 0.8977\n",
            "Epoch 16/100\n",
            " - 4s - loss: 0.1417 - accuracy: 0.9467 - val_loss: 0.3732 - val_accuracy: 0.8932\n",
            "Epoch 17/100\n",
            " - 4s - loss: 0.1362 - accuracy: 0.9500 - val_loss: 0.3677 - val_accuracy: 0.8969\n",
            "Epoch 18/100\n",
            " - 4s - loss: 0.1318 - accuracy: 0.9509 - val_loss: 0.3767 - val_accuracy: 0.8896\n",
            "Epoch 19/100\n",
            " - 4s - loss: 0.1227 - accuracy: 0.9538 - val_loss: 0.3687 - val_accuracy: 0.8969\n",
            "Epoch 20/100\n",
            " - 4s - loss: 0.1172 - accuracy: 0.9557 - val_loss: 0.3829 - val_accuracy: 0.8965\n",
            "Epoch 21/100\n",
            " - 4s - loss: 0.1170 - accuracy: 0.9568 - val_loss: 0.3988 - val_accuracy: 0.8940\n",
            "Epoch 22/100\n",
            " - 4s - loss: 0.1115 - accuracy: 0.9579 - val_loss: 0.4084 - val_accuracy: 0.8943\n",
            "Epoch 23/100\n",
            " - 4s - loss: 0.1040 - accuracy: 0.9608 - val_loss: 0.4017 - val_accuracy: 0.8965\n",
            "Epoch 24/100\n",
            " - 4s - loss: 0.0992 - accuracy: 0.9631 - val_loss: 0.4041 - val_accuracy: 0.8980\n",
            "Epoch 25/100\n",
            " - 4s - loss: 0.0976 - accuracy: 0.9642 - val_loss: 0.4295 - val_accuracy: 0.8940\n",
            "Epoch 26/100\n",
            " - 4s - loss: 0.0908 - accuracy: 0.9660 - val_loss: 0.4546 - val_accuracy: 0.8920\n",
            "Epoch 27/100\n",
            " - 4s - loss: 0.0956 - accuracy: 0.9651 - val_loss: 0.4356 - val_accuracy: 0.8927\n",
            "Epoch 28/100\n",
            " - 4s - loss: 0.0924 - accuracy: 0.9650 - val_loss: 0.4456 - val_accuracy: 0.8928\n",
            "Epoch 29/100\n",
            " - 4s - loss: 0.0811 - accuracy: 0.9697 - val_loss: 0.4498 - val_accuracy: 0.8940\n",
            "Epoch 30/100\n",
            " - 4s - loss: 0.0814 - accuracy: 0.9699 - val_loss: 0.4508 - val_accuracy: 0.8923\n",
            "Epoch 31/100\n",
            " - 4s - loss: 0.0769 - accuracy: 0.9709 - val_loss: 0.4560 - val_accuracy: 0.8933\n",
            "Epoch 32/100\n",
            " - 4s - loss: 0.0745 - accuracy: 0.9725 - val_loss: 0.4715 - val_accuracy: 0.8919\n",
            "Epoch 33/100\n",
            " - 4s - loss: 0.0726 - accuracy: 0.9732 - val_loss: 0.4890 - val_accuracy: 0.8917\n",
            "Epoch 34/100\n",
            " - 4s - loss: 0.0684 - accuracy: 0.9746 - val_loss: 0.5012 - val_accuracy: 0.8958\n",
            "Epoch 35/100\n",
            " - 4s - loss: 0.0709 - accuracy: 0.9737 - val_loss: 0.5005 - val_accuracy: 0.8925\n",
            "Epoch 36/100\n",
            " - 4s - loss: 0.0726 - accuracy: 0.9727 - val_loss: 0.5346 - val_accuracy: 0.8921\n",
            "Epoch 37/100\n",
            " - 4s - loss: 0.0619 - accuracy: 0.9773 - val_loss: 0.5054 - val_accuracy: 0.8956\n",
            "Epoch 38/100\n",
            " - 4s - loss: 0.0631 - accuracy: 0.9773 - val_loss: 0.5175 - val_accuracy: 0.8933\n",
            "Epoch 39/100\n",
            " - 4s - loss: 0.0643 - accuracy: 0.9763 - val_loss: 0.5192 - val_accuracy: 0.8913\n",
            "Epoch 40/100\n",
            " - 4s - loss: 0.0553 - accuracy: 0.9796 - val_loss: 0.5340 - val_accuracy: 0.8955\n",
            "Epoch 41/100\n",
            " - 4s - loss: 0.0620 - accuracy: 0.9775 - val_loss: 0.5898 - val_accuracy: 0.8935\n",
            "Epoch 42/100\n",
            " - 4s - loss: 0.0588 - accuracy: 0.9791 - val_loss: 0.5667 - val_accuracy: 0.8900\n",
            "Epoch 43/100\n",
            " - 4s - loss: 0.0514 - accuracy: 0.9809 - val_loss: 0.5952 - val_accuracy: 0.8900\n",
            "Epoch 44/100\n",
            " - 4s - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.5795 - val_accuracy: 0.8932\n",
            "Epoch 45/100\n",
            " - 4s - loss: 0.0497 - accuracy: 0.9812 - val_loss: 0.5653 - val_accuracy: 0.8914\n",
            "Epoch 46/100\n",
            " - 4s - loss: 0.0500 - accuracy: 0.9813 - val_loss: 0.5647 - val_accuracy: 0.8926\n",
            "Epoch 47/100\n",
            " - 4s - loss: 0.0495 - accuracy: 0.9821 - val_loss: 0.5667 - val_accuracy: 0.8924\n",
            "Epoch 48/100\n",
            " - 4s - loss: 0.0506 - accuracy: 0.9818 - val_loss: 0.6019 - val_accuracy: 0.8860\n",
            "Epoch 49/100\n",
            " - 4s - loss: 0.0528 - accuracy: 0.9809 - val_loss: 0.6229 - val_accuracy: 0.8887\n",
            "Epoch 50/100\n",
            " - 4s - loss: 0.0445 - accuracy: 0.9839 - val_loss: 0.6101 - val_accuracy: 0.8942\n",
            "Epoch 51/100\n",
            " - 4s - loss: 0.0436 - accuracy: 0.9837 - val_loss: 0.6329 - val_accuracy: 0.8915\n",
            "Epoch 52/100\n",
            " - 4s - loss: 0.0424 - accuracy: 0.9848 - val_loss: 0.6284 - val_accuracy: 0.8942\n",
            "Epoch 53/100\n",
            " - 4s - loss: 0.0471 - accuracy: 0.9834 - val_loss: 0.6267 - val_accuracy: 0.8917\n",
            "Epoch 54/100\n",
            " - 4s - loss: 0.0393 - accuracy: 0.9860 - val_loss: 0.6262 - val_accuracy: 0.8955\n",
            "Epoch 55/100\n",
            " - 4s - loss: 0.0317 - accuracy: 0.9885 - val_loss: 0.6416 - val_accuracy: 0.8921\n",
            "Epoch 56/100\n",
            " - 4s - loss: 0.0403 - accuracy: 0.9853 - val_loss: 0.6862 - val_accuracy: 0.8867\n",
            "Epoch 57/100\n",
            " - 4s - loss: 0.0377 - accuracy: 0.9857 - val_loss: 0.6513 - val_accuracy: 0.8968\n",
            "Epoch 58/100\n",
            " - 4s - loss: 0.0440 - accuracy: 0.9851 - val_loss: 0.6661 - val_accuracy: 0.8932\n",
            "Epoch 59/100\n",
            " - 4s - loss: 0.0573 - accuracy: 0.9809 - val_loss: 0.6932 - val_accuracy: 0.8896\n",
            "Epoch 60/100\n",
            " - 4s - loss: 0.0340 - accuracy: 0.9876 - val_loss: 0.6865 - val_accuracy: 0.8909\n",
            "Epoch 61/100\n",
            " - 4s - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.7020 - val_accuracy: 0.8904\n",
            "Epoch 62/100\n",
            " - 4s - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.6936 - val_accuracy: 0.8933\n",
            "Epoch 63/100\n",
            " - 4s - loss: 0.0360 - accuracy: 0.9876 - val_loss: 0.7283 - val_accuracy: 0.8913\n",
            "Epoch 64/100\n",
            " - 4s - loss: 0.0440 - accuracy: 0.9836 - val_loss: 0.7109 - val_accuracy: 0.8958\n",
            "Epoch 65/100\n",
            " - 4s - loss: 0.0336 - accuracy: 0.9880 - val_loss: 0.7185 - val_accuracy: 0.8931\n",
            "Epoch 66/100\n",
            " - 4s - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.7142 - val_accuracy: 0.8887\n",
            "Epoch 67/100\n",
            " - 4s - loss: 0.0310 - accuracy: 0.9889 - val_loss: 0.7578 - val_accuracy: 0.8870\n",
            "Epoch 68/100\n",
            " - 4s - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.8119 - val_accuracy: 0.8887\n",
            "Epoch 69/100\n",
            " - 4s - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.7613 - val_accuracy: 0.8908\n",
            "Epoch 70/100\n",
            " - 4s - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.7553 - val_accuracy: 0.8933\n",
            "Epoch 71/100\n",
            " - 4s - loss: 0.0232 - accuracy: 0.9914 - val_loss: 0.7520 - val_accuracy: 0.8907\n",
            "Epoch 72/100\n",
            " - 4s - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.7501 - val_accuracy: 0.8941\n",
            "Epoch 73/100\n",
            " - 4s - loss: 0.0344 - accuracy: 0.9877 - val_loss: 0.7649 - val_accuracy: 0.8895\n",
            "Epoch 74/100\n",
            " - 4s - loss: 0.0301 - accuracy: 0.9891 - val_loss: 0.8116 - val_accuracy: 0.8893\n",
            "Epoch 75/100\n",
            " - 4s - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.7801 - val_accuracy: 0.8935\n",
            "Epoch 76/100\n",
            " - 4s - loss: 0.0304 - accuracy: 0.9893 - val_loss: 0.7900 - val_accuracy: 0.8917\n",
            "Epoch 77/100\n",
            " - 4s - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.7690 - val_accuracy: 0.8959\n",
            "Epoch 78/100\n",
            " - 4s - loss: 0.0193 - accuracy: 0.9930 - val_loss: 0.7701 - val_accuracy: 0.8982\n",
            "Epoch 79/100\n",
            " - 4s - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.8187 - val_accuracy: 0.8914\n",
            "Epoch 80/100\n",
            " - 4s - loss: 0.0447 - accuracy: 0.9852 - val_loss: 0.7982 - val_accuracy: 0.8899\n",
            "Epoch 81/100\n",
            " - 4s - loss: 0.0318 - accuracy: 0.9894 - val_loss: 0.8321 - val_accuracy: 0.8893\n",
            "Epoch 82/100\n",
            " - 4s - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.8141 - val_accuracy: 0.8952\n",
            "Epoch 83/100\n",
            " - 4s - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.8183 - val_accuracy: 0.8958\n",
            "Epoch 84/100\n",
            " - 4s - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.8361 - val_accuracy: 0.8946\n",
            "Epoch 85/100\n",
            " - 4s - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.8572 - val_accuracy: 0.8907\n",
            "Epoch 86/100\n",
            " - 4s - loss: 0.0278 - accuracy: 0.9901 - val_loss: 0.8421 - val_accuracy: 0.8898\n",
            "Epoch 87/100\n",
            " - 4s - loss: 0.0326 - accuracy: 0.9888 - val_loss: 0.8527 - val_accuracy: 0.8889\n",
            "Epoch 88/100\n",
            " - 4s - loss: 0.0206 - accuracy: 0.9930 - val_loss: 0.8454 - val_accuracy: 0.8933\n",
            "Epoch 89/100\n",
            " - 4s - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.8756 - val_accuracy: 0.8939\n",
            "Epoch 90/100\n",
            " - 4s - loss: 0.0280 - accuracy: 0.9899 - val_loss: 0.9228 - val_accuracy: 0.8860\n",
            "Epoch 91/100\n",
            " - 4s - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.8471 - val_accuracy: 0.8933\n",
            "Epoch 92/100\n",
            " - 4s - loss: 0.0267 - accuracy: 0.9919 - val_loss: 0.9337 - val_accuracy: 0.8917\n",
            "Epoch 93/100\n",
            " - 4s - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.8785 - val_accuracy: 0.8970\n",
            "Epoch 94/100\n",
            " - 4s - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.8720 - val_accuracy: 0.8956\n",
            "Epoch 95/100\n",
            " - 4s - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.9090 - val_accuracy: 0.8938\n",
            "Epoch 96/100\n",
            " - 4s - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.9550 - val_accuracy: 0.8908\n",
            "Epoch 97/100\n",
            " - 4s - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.9894 - val_accuracy: 0.8837\n",
            "Epoch 98/100\n",
            " - 4s - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.8995 - val_accuracy: 0.8930\n",
            "Epoch 99/100\n",
            " - 4s - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.9434 - val_accuracy: 0.8956\n",
            "Epoch 100/100\n",
            " - 4s - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.9596 - val_accuracy: 0.8932\n",
            "Baseline Error: 10.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fSZha2PggRi"
      },
      "source": [
        "### 4. Build the CNN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FpsA7ZkIgygc",
        "colab": {}
      },
      "source": [
        "# load (downloaded if needed) the fashiom_mnist dataset \n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBaH2HZSXvj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "mean = np.mean(X_train)\n",
        "stddev = np.std(X_train)\n",
        "#scale\n",
        "X_train = (X_train - mean) / stddev\n",
        "X_test = (X_test - mean) / stddev\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2MU56deXvkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a simple CNN model\n",
        "def baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dNbipqZHHDJY"
      },
      "source": [
        "### 5. Compile fit, and evaluate the model and print the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLSK1Yc6iE3b",
        "colab_type": "code",
        "outputId": "c63c92f1-e723-43db-c37e-51382e4dfedc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=200,\n",
        "    verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            " - 28s - loss: 0.4436 - accuracy: 0.8403 - val_loss: 0.3440 - val_accuracy: 0.8763\n",
            "Epoch 2/100\n",
            " - 28s - loss: 0.3054 - accuracy: 0.8888 - val_loss: 0.3031 - val_accuracy: 0.8903\n",
            "Epoch 3/100\n",
            " - 28s - loss: 0.2638 - accuracy: 0.9039 - val_loss: 0.2833 - val_accuracy: 0.8972\n",
            "Epoch 4/100\n",
            " - 28s - loss: 0.2370 - accuracy: 0.9138 - val_loss: 0.2740 - val_accuracy: 0.8982\n",
            "Epoch 5/100\n",
            " - 28s - loss: 0.2161 - accuracy: 0.9205 - val_loss: 0.2576 - val_accuracy: 0.9040\n",
            "Epoch 6/100\n",
            " - 28s - loss: 0.2011 - accuracy: 0.9252 - val_loss: 0.2499 - val_accuracy: 0.9109\n",
            "Epoch 7/100\n",
            " - 28s - loss: 0.1854 - accuracy: 0.9316 - val_loss: 0.2496 - val_accuracy: 0.9110\n",
            "Epoch 8/100\n",
            " - 28s - loss: 0.1716 - accuracy: 0.9354 - val_loss: 0.2419 - val_accuracy: 0.9135\n",
            "Epoch 9/100\n",
            " - 28s - loss: 0.1574 - accuracy: 0.9411 - val_loss: 0.2464 - val_accuracy: 0.9108\n",
            "Epoch 10/100\n",
            " - 28s - loss: 0.1431 - accuracy: 0.9468 - val_loss: 0.2506 - val_accuracy: 0.9131\n",
            "Epoch 11/100\n",
            " - 28s - loss: 0.1337 - accuracy: 0.9496 - val_loss: 0.2471 - val_accuracy: 0.9180\n",
            "Epoch 12/100\n",
            " - 28s - loss: 0.1237 - accuracy: 0.9535 - val_loss: 0.2686 - val_accuracy: 0.9078\n",
            "Epoch 13/100\n",
            " - 28s - loss: 0.1138 - accuracy: 0.9581 - val_loss: 0.2537 - val_accuracy: 0.9172\n",
            "Epoch 14/100\n",
            " - 28s - loss: 0.1075 - accuracy: 0.9596 - val_loss: 0.2623 - val_accuracy: 0.9202\n",
            "Epoch 15/100\n",
            " - 28s - loss: 0.1002 - accuracy: 0.9624 - val_loss: 0.2666 - val_accuracy: 0.9195\n",
            "Epoch 16/100\n",
            " - 27s - loss: 0.0929 - accuracy: 0.9653 - val_loss: 0.2804 - val_accuracy: 0.9132\n",
            "Epoch 17/100\n",
            " - 28s - loss: 0.0881 - accuracy: 0.9678 - val_loss: 0.2751 - val_accuracy: 0.9183\n",
            "Epoch 18/100\n",
            " - 27s - loss: 0.0781 - accuracy: 0.9717 - val_loss: 0.2878 - val_accuracy: 0.9182\n",
            "Epoch 19/100\n",
            " - 27s - loss: 0.0748 - accuracy: 0.9724 - val_loss: 0.2926 - val_accuracy: 0.9184\n",
            "Epoch 20/100\n",
            " - 27s - loss: 0.0731 - accuracy: 0.9724 - val_loss: 0.3003 - val_accuracy: 0.9178\n",
            "Epoch 21/100\n",
            " - 28s - loss: 0.0680 - accuracy: 0.9748 - val_loss: 0.3340 - val_accuracy: 0.9149\n",
            "Epoch 22/100\n",
            " - 27s - loss: 0.0633 - accuracy: 0.9760 - val_loss: 0.3039 - val_accuracy: 0.9204\n",
            "Epoch 23/100\n",
            " - 28s - loss: 0.0579 - accuracy: 0.9782 - val_loss: 0.3299 - val_accuracy: 0.9198\n",
            "Epoch 24/100\n",
            " - 27s - loss: 0.0563 - accuracy: 0.9788 - val_loss: 0.3350 - val_accuracy: 0.9201\n",
            "Epoch 25/100\n",
            " - 27s - loss: 0.0497 - accuracy: 0.9819 - val_loss: 0.3401 - val_accuracy: 0.9214\n",
            "Epoch 26/100\n",
            " - 27s - loss: 0.0473 - accuracy: 0.9830 - val_loss: 0.3591 - val_accuracy: 0.9200\n",
            "Epoch 27/100\n",
            " - 27s - loss: 0.0482 - accuracy: 0.9816 - val_loss: 0.3582 - val_accuracy: 0.9164\n",
            "Epoch 28/100\n",
            " - 27s - loss: 0.0440 - accuracy: 0.9839 - val_loss: 0.3589 - val_accuracy: 0.9184\n",
            "Epoch 29/100\n",
            " - 27s - loss: 0.0420 - accuracy: 0.9851 - val_loss: 0.3602 - val_accuracy: 0.9167\n",
            "Epoch 30/100\n",
            " - 27s - loss: 0.0424 - accuracy: 0.9845 - val_loss: 0.3642 - val_accuracy: 0.9171\n",
            "Epoch 31/100\n",
            " - 27s - loss: 0.0398 - accuracy: 0.9855 - val_loss: 0.3895 - val_accuracy: 0.9167\n",
            "Epoch 32/100\n",
            " - 27s - loss: 0.0385 - accuracy: 0.9860 - val_loss: 0.3968 - val_accuracy: 0.9184\n",
            "Epoch 33/100\n",
            " - 28s - loss: 0.0396 - accuracy: 0.9855 - val_loss: 0.3994 - val_accuracy: 0.9185\n",
            "Epoch 34/100\n",
            " - 28s - loss: 0.0369 - accuracy: 0.9866 - val_loss: 0.4140 - val_accuracy: 0.9113\n",
            "Epoch 35/100\n",
            " - 27s - loss: 0.0332 - accuracy: 0.9876 - val_loss: 0.4057 - val_accuracy: 0.9174\n",
            "Epoch 36/100\n",
            " - 27s - loss: 0.0314 - accuracy: 0.9888 - val_loss: 0.4340 - val_accuracy: 0.9147\n",
            "Epoch 37/100\n",
            " - 27s - loss: 0.0296 - accuracy: 0.9895 - val_loss: 0.4326 - val_accuracy: 0.9166\n",
            "Epoch 38/100\n",
            " - 27s - loss: 0.0282 - accuracy: 0.9901 - val_loss: 0.4401 - val_accuracy: 0.9133\n",
            "Epoch 39/100\n",
            " - 28s - loss: 0.0302 - accuracy: 0.9892 - val_loss: 0.4489 - val_accuracy: 0.9151\n",
            "Epoch 40/100\n",
            " - 27s - loss: 0.0292 - accuracy: 0.9898 - val_loss: 0.4542 - val_accuracy: 0.9153\n",
            "Epoch 41/100\n",
            " - 28s - loss: 0.0290 - accuracy: 0.9900 - val_loss: 0.4514 - val_accuracy: 0.9156\n",
            "Epoch 42/100\n",
            " - 27s - loss: 0.0283 - accuracy: 0.9902 - val_loss: 0.4856 - val_accuracy: 0.9139\n",
            "Epoch 43/100\n",
            " - 27s - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.4693 - val_accuracy: 0.9150\n",
            "Epoch 44/100\n",
            " - 27s - loss: 0.0253 - accuracy: 0.9905 - val_loss: 0.4651 - val_accuracy: 0.9124\n",
            "Epoch 45/100\n",
            " - 28s - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.4683 - val_accuracy: 0.9179\n",
            "Epoch 46/100\n",
            " - 27s - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.4614 - val_accuracy: 0.9150\n",
            "Epoch 47/100\n",
            " - 27s - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.4896 - val_accuracy: 0.9157\n",
            "Epoch 48/100\n",
            " - 27s - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.5168 - val_accuracy: 0.9134\n",
            "Epoch 49/100\n",
            " - 27s - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.4989 - val_accuracy: 0.9164\n",
            "Epoch 50/100\n",
            " - 27s - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.5005 - val_accuracy: 0.9171\n",
            "Epoch 51/100\n",
            " - 27s - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.5134 - val_accuracy: 0.9158\n",
            "Epoch 52/100\n",
            " - 28s - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.5087 - val_accuracy: 0.9160\n",
            "Epoch 53/100\n",
            " - 28s - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.5182 - val_accuracy: 0.9165\n",
            "Epoch 54/100\n",
            " - 28s - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.5101 - val_accuracy: 0.9161\n",
            "Epoch 55/100\n",
            " - 28s - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.5110 - val_accuracy: 0.9151\n",
            "Epoch 56/100\n",
            " - 28s - loss: 0.0214 - accuracy: 0.9923 - val_loss: 0.5039 - val_accuracy: 0.9165\n",
            "Epoch 57/100\n",
            " - 28s - loss: 0.0182 - accuracy: 0.9935 - val_loss: 0.5278 - val_accuracy: 0.9158\n",
            "Epoch 58/100\n",
            " - 28s - loss: 0.0196 - accuracy: 0.9929 - val_loss: 0.5513 - val_accuracy: 0.9131\n",
            "Epoch 59/100\n",
            " - 28s - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.5213 - val_accuracy: 0.9165\n",
            "Epoch 60/100\n",
            " - 28s - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.5629 - val_accuracy: 0.9157\n",
            "Epoch 61/100\n",
            " - 28s - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.5524 - val_accuracy: 0.9149\n",
            "Epoch 62/100\n",
            " - 27s - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.5572 - val_accuracy: 0.9157\n",
            "Epoch 63/100\n",
            " - 28s - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.5496 - val_accuracy: 0.9168\n",
            "Epoch 64/100\n",
            " - 27s - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.5600 - val_accuracy: 0.9177\n",
            "Epoch 65/100\n",
            " - 28s - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.5584 - val_accuracy: 0.9169\n",
            "Epoch 66/100\n",
            " - 32s - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.5897 - val_accuracy: 0.9153\n",
            "Epoch 67/100\n",
            " - 28s - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.5662 - val_accuracy: 0.9183\n",
            "Epoch 68/100\n",
            " - 28s - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.5994 - val_accuracy: 0.9146\n",
            "Epoch 69/100\n",
            " - 28s - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.5727 - val_accuracy: 0.9186\n",
            "Epoch 70/100\n",
            " - 28s - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.5899 - val_accuracy: 0.9156\n",
            "Epoch 71/100\n",
            " - 28s - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.5821 - val_accuracy: 0.9162\n",
            "Epoch 72/100\n",
            " - 28s - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.6182 - val_accuracy: 0.9133\n",
            "Epoch 73/100\n",
            " - 28s - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.5958 - val_accuracy: 0.9149\n",
            "Epoch 74/100\n",
            " - 28s - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.6179 - val_accuracy: 0.9169\n",
            "Epoch 75/100\n",
            " - 28s - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.6207 - val_accuracy: 0.9146\n",
            "Epoch 76/100\n",
            " - 28s - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.6504 - val_accuracy: 0.9133\n",
            "Epoch 77/100\n",
            " - 28s - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.6187 - val_accuracy: 0.9139\n",
            "Epoch 78/100\n",
            " - 28s - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.6492 - val_accuracy: 0.9115\n",
            "Epoch 79/100\n",
            " - 28s - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.6282 - val_accuracy: 0.9145\n",
            "Epoch 80/100\n",
            " - 27s - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.6163 - val_accuracy: 0.9169\n",
            "Epoch 81/100\n",
            " - 28s - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.6231 - val_accuracy: 0.9162\n",
            "Epoch 82/100\n",
            " - 28s - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.6340 - val_accuracy: 0.9181\n",
            "Epoch 83/100\n",
            " - 28s - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.6143 - val_accuracy: 0.9175\n",
            "Epoch 84/100\n",
            " - 28s - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.6586 - val_accuracy: 0.9114\n",
            "Epoch 85/100\n",
            " - 27s - loss: 0.0168 - accuracy: 0.9941 - val_loss: 0.6199 - val_accuracy: 0.9141\n",
            "Epoch 86/100\n",
            " - 28s - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.6497 - val_accuracy: 0.9159\n",
            "Epoch 87/100\n",
            " - 28s - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.6302 - val_accuracy: 0.9164\n",
            "Epoch 88/100\n",
            " - 33s - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.6722 - val_accuracy: 0.9133\n",
            "Epoch 89/100\n",
            " - 28s - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.6445 - val_accuracy: 0.9152\n",
            "Epoch 90/100\n",
            " - 28s - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.6834 - val_accuracy: 0.9150\n",
            "Epoch 91/100\n",
            " - 28s - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.6849 - val_accuracy: 0.9106\n",
            "Epoch 92/100\n",
            " - 28s - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.6632 - val_accuracy: 0.9133\n",
            "Epoch 93/100\n",
            " - 28s - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.6793 - val_accuracy: 0.9147\n",
            "Epoch 94/100\n",
            " - 27s - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.7223 - val_accuracy: 0.9153\n",
            "Epoch 95/100\n",
            " - 28s - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.7226 - val_accuracy: 0.9117\n",
            "Epoch 96/100\n",
            " - 28s - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.6859 - val_accuracy: 0.9140\n",
            "Epoch 97/100\n",
            " - 28s - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.7038 - val_accuracy: 0.9139\n",
            "Epoch 98/100\n",
            " - 28s - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.6771 - val_accuracy: 0.9147\n",
            "Epoch 99/100\n",
            " - 28s - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.6762 - val_accuracy: 0.9121\n",
            "Epoch 100/100\n",
            " - 27s - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.7069 - val_accuracy: 0.9141\n",
            "CNN Baseline Error: 8.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiMoCGNMbPqh",
        "colab_type": "code",
        "outputId": "42fabe9f-a8c1-4566-949e-4a500c2145a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Larger CNN for the fashion fashion_mnist Dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# define the larger model\n",
        "def larger_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D()) \n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "# build the model\n",
        "model = larger_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=200)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Large CNN Error for fashion_mnist: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 35s 585us/step - loss: 0.7584 - accuracy: 0.7162 - val_loss: 0.5321 - val_accuracy: 0.7991\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 35s 582us/step - loss: 0.4708 - accuracy: 0.8291 - val_loss: 0.4133 - val_accuracy: 0.8524\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 35s 584us/step - loss: 0.4024 - accuracy: 0.8527 - val_loss: 0.3673 - val_accuracy: 0.8683\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 35s 585us/step - loss: 0.3680 - accuracy: 0.8657 - val_loss: 0.3489 - val_accuracy: 0.8737\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.3439 - accuracy: 0.8752 - val_loss: 0.3388 - val_accuracy: 0.8775\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 35s 585us/step - loss: 0.3245 - accuracy: 0.8810 - val_loss: 0.3167 - val_accuracy: 0.8855\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 35s 584us/step - loss: 0.3114 - accuracy: 0.8861 - val_loss: 0.3056 - val_accuracy: 0.8908\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 35s 582us/step - loss: 0.2963 - accuracy: 0.8907 - val_loss: 0.2934 - val_accuracy: 0.8946\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 35s 582us/step - loss: 0.2860 - accuracy: 0.8952 - val_loss: 0.2859 - val_accuracy: 0.8942\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 35s 584us/step - loss: 0.2793 - accuracy: 0.8964 - val_loss: 0.2857 - val_accuracy: 0.8975\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.2712 - accuracy: 0.8997 - val_loss: 0.2871 - val_accuracy: 0.8938\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.2617 - accuracy: 0.9035 - val_loss: 0.2825 - val_accuracy: 0.8963\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.2539 - accuracy: 0.9069 - val_loss: 0.2732 - val_accuracy: 0.9020\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 35s 581us/step - loss: 0.2486 - accuracy: 0.9077 - val_loss: 0.2753 - val_accuracy: 0.8961\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.2389 - accuracy: 0.9114 - val_loss: 0.2692 - val_accuracy: 0.9018\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 35s 588us/step - loss: 0.2319 - accuracy: 0.9139 - val_loss: 0.2541 - val_accuracy: 0.9100\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 39s 652us/step - loss: 0.2296 - accuracy: 0.9134 - val_loss: 0.2568 - val_accuracy: 0.9063\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.2265 - accuracy: 0.9155 - val_loss: 0.2541 - val_accuracy: 0.9096\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.2228 - accuracy: 0.9158 - val_loss: 0.2563 - val_accuracy: 0.9069\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 35s 581us/step - loss: 0.2146 - accuracy: 0.9199 - val_loss: 0.2546 - val_accuracy: 0.9090\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 35s 581us/step - loss: 0.2108 - accuracy: 0.9205 - val_loss: 0.2442 - val_accuracy: 0.9112\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.2054 - accuracy: 0.9226 - val_loss: 0.2512 - val_accuracy: 0.9104\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 35s 582us/step - loss: 0.2054 - accuracy: 0.9214 - val_loss: 0.2397 - val_accuracy: 0.9139\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.1992 - accuracy: 0.9248 - val_loss: 0.2433 - val_accuracy: 0.9129\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 35s 577us/step - loss: 0.1959 - accuracy: 0.9262 - val_loss: 0.2476 - val_accuracy: 0.9130\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 35s 576us/step - loss: 0.1938 - accuracy: 0.9266 - val_loss: 0.2417 - val_accuracy: 0.9167\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 35s 581us/step - loss: 0.1929 - accuracy: 0.9270 - val_loss: 0.2414 - val_accuracy: 0.9127\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.1858 - accuracy: 0.9300 - val_loss: 0.2499 - val_accuracy: 0.9124\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 35s 579us/step - loss: 0.1837 - accuracy: 0.9302 - val_loss: 0.2421 - val_accuracy: 0.9157\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 35s 577us/step - loss: 0.1809 - accuracy: 0.9310 - val_loss: 0.2432 - val_accuracy: 0.9136\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.1757 - accuracy: 0.9331 - val_loss: 0.2461 - val_accuracy: 0.9158\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 35s 579us/step - loss: 0.1713 - accuracy: 0.9347 - val_loss: 0.2396 - val_accuracy: 0.9166\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 35s 579us/step - loss: 0.1735 - accuracy: 0.9341 - val_loss: 0.2424 - val_accuracy: 0.9169\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 40s 669us/step - loss: 0.1676 - accuracy: 0.9357 - val_loss: 0.2491 - val_accuracy: 0.9167\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 35s 579us/step - loss: 0.1643 - accuracy: 0.9376 - val_loss: 0.2452 - val_accuracy: 0.9172\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 35s 575us/step - loss: 0.1649 - accuracy: 0.9372 - val_loss: 0.2443 - val_accuracy: 0.9198\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.1581 - accuracy: 0.9401 - val_loss: 0.2441 - val_accuracy: 0.9174\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 34s 573us/step - loss: 0.1601 - accuracy: 0.9386 - val_loss: 0.2457 - val_accuracy: 0.9180\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 34s 574us/step - loss: 0.1549 - accuracy: 0.9407 - val_loss: 0.2431 - val_accuracy: 0.9192\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 35s 578us/step - loss: 0.1530 - accuracy: 0.9419 - val_loss: 0.2482 - val_accuracy: 0.9173\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 35s 576us/step - loss: 0.1533 - accuracy: 0.9416 - val_loss: 0.2519 - val_accuracy: 0.9157\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 34s 567us/step - loss: 0.1504 - accuracy: 0.9420 - val_loss: 0.2464 - val_accuracy: 0.9189\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 36s 604us/step - loss: 0.1504 - accuracy: 0.9427 - val_loss: 0.2520 - val_accuracy: 0.9159\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 35s 587us/step - loss: 0.1478 - accuracy: 0.9435 - val_loss: 0.2491 - val_accuracy: 0.9177\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 35s 587us/step - loss: 0.1445 - accuracy: 0.9447 - val_loss: 0.2661 - val_accuracy: 0.9113\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 35s 585us/step - loss: 0.1427 - accuracy: 0.9458 - val_loss: 0.2644 - val_accuracy: 0.9124\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1404 - accuracy: 0.9458 - val_loss: 0.2525 - val_accuracy: 0.9174\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 35s 585us/step - loss: 0.1408 - accuracy: 0.9467 - val_loss: 0.2499 - val_accuracy: 0.9181\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1358 - accuracy: 0.9475 - val_loss: 0.2541 - val_accuracy: 0.9197\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 37s 611us/step - loss: 0.1363 - accuracy: 0.9477 - val_loss: 0.2652 - val_accuracy: 0.9172\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 41s 676us/step - loss: 0.1331 - accuracy: 0.9489 - val_loss: 0.2611 - val_accuracy: 0.9154\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 35s 585us/step - loss: 0.1322 - accuracy: 0.9492 - val_loss: 0.2588 - val_accuracy: 0.9205\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 35s 581us/step - loss: 0.1298 - accuracy: 0.9508 - val_loss: 0.2533 - val_accuracy: 0.9213\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 35s 585us/step - loss: 0.1292 - accuracy: 0.9498 - val_loss: 0.2493 - val_accuracy: 0.9210\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 35s 582us/step - loss: 0.1275 - accuracy: 0.9510 - val_loss: 0.2659 - val_accuracy: 0.9162\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 35s 582us/step - loss: 0.1278 - accuracy: 0.9516 - val_loss: 0.2651 - val_accuracy: 0.9187\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1247 - accuracy: 0.9523 - val_loss: 0.2765 - val_accuracy: 0.9132\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 35s 586us/step - loss: 0.1230 - accuracy: 0.9524 - val_loss: 0.2603 - val_accuracy: 0.9198\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 35s 586us/step - loss: 0.1215 - accuracy: 0.9535 - val_loss: 0.2596 - val_accuracy: 0.9192\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1238 - accuracy: 0.9513 - val_loss: 0.2893 - val_accuracy: 0.9144\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 35s 584us/step - loss: 0.1201 - accuracy: 0.9535 - val_loss: 0.2751 - val_accuracy: 0.9177\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 35s 585us/step - loss: 0.1185 - accuracy: 0.9549 - val_loss: 0.2696 - val_accuracy: 0.9174\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 35s 582us/step - loss: 0.1157 - accuracy: 0.9558 - val_loss: 0.2719 - val_accuracy: 0.9151\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1176 - accuracy: 0.9553 - val_loss: 0.2706 - val_accuracy: 0.9179\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 35s 578us/step - loss: 0.1171 - accuracy: 0.9549 - val_loss: 0.2722 - val_accuracy: 0.9175\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 35s 576us/step - loss: 0.1182 - accuracy: 0.9551 - val_loss: 0.2778 - val_accuracy: 0.9145\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 34s 571us/step - loss: 0.1134 - accuracy: 0.9559 - val_loss: 0.2775 - val_accuracy: 0.9176\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 38s 629us/step - loss: 0.1135 - accuracy: 0.9559 - val_loss: 0.2760 - val_accuracy: 0.9179\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 39s 652us/step - loss: 0.1114 - accuracy: 0.9578 - val_loss: 0.2768 - val_accuracy: 0.9173\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1088 - accuracy: 0.9587 - val_loss: 0.2663 - val_accuracy: 0.9205\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 35s 577us/step - loss: 0.1139 - accuracy: 0.9563 - val_loss: 0.2874 - val_accuracy: 0.9128\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.1121 - accuracy: 0.9565 - val_loss: 0.2745 - val_accuracy: 0.9174\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 35s 581us/step - loss: 0.1082 - accuracy: 0.9582 - val_loss: 0.2923 - val_accuracy: 0.9160\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1069 - accuracy: 0.9588 - val_loss: 0.3014 - val_accuracy: 0.9088\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1084 - accuracy: 0.9587 - val_loss: 0.2922 - val_accuracy: 0.9162\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1066 - accuracy: 0.9590 - val_loss: 0.2780 - val_accuracy: 0.9177\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 35s 581us/step - loss: 0.1074 - accuracy: 0.9584 - val_loss: 0.2858 - val_accuracy: 0.9194\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.1027 - accuracy: 0.9606 - val_loss: 0.3035 - val_accuracy: 0.9137\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 35s 578us/step - loss: 0.1023 - accuracy: 0.9605 - val_loss: 0.2997 - val_accuracy: 0.9177\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.1027 - accuracy: 0.9610 - val_loss: 0.2855 - val_accuracy: 0.9194\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 35s 582us/step - loss: 0.1006 - accuracy: 0.9614 - val_loss: 0.2878 - val_accuracy: 0.9174\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 35s 578us/step - loss: 0.1022 - accuracy: 0.9605 - val_loss: 0.2884 - val_accuracy: 0.9188\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 35s 578us/step - loss: 0.1035 - accuracy: 0.9603 - val_loss: 0.2959 - val_accuracy: 0.9180\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 35s 584us/step - loss: 0.0981 - accuracy: 0.9622 - val_loss: 0.2913 - val_accuracy: 0.9180\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 35s 579us/step - loss: 0.0969 - accuracy: 0.9637 - val_loss: 0.2945 - val_accuracy: 0.9198\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 40s 673us/step - loss: 0.0991 - accuracy: 0.9622 - val_loss: 0.2901 - val_accuracy: 0.9177\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 35s 577us/step - loss: 0.0971 - accuracy: 0.9633 - val_loss: 0.2877 - val_accuracy: 0.9182\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.0950 - accuracy: 0.9639 - val_loss: 0.3027 - val_accuracy: 0.9168\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.0950 - accuracy: 0.9639 - val_loss: 0.3064 - val_accuracy: 0.9166\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 35s 578us/step - loss: 0.0996 - accuracy: 0.9627 - val_loss: 0.3067 - val_accuracy: 0.9156\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 35s 579us/step - loss: 0.0967 - accuracy: 0.9628 - val_loss: 0.3079 - val_accuracy: 0.9176\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 34s 574us/step - loss: 0.0990 - accuracy: 0.9617 - val_loss: 0.3030 - val_accuracy: 0.9176\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 35s 579us/step - loss: 0.0935 - accuracy: 0.9649 - val_loss: 0.2965 - val_accuracy: 0.9203\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 35s 580us/step - loss: 0.0928 - accuracy: 0.9650 - val_loss: 0.2962 - val_accuracy: 0.9188\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 34s 574us/step - loss: 0.0947 - accuracy: 0.9635 - val_loss: 0.3015 - val_accuracy: 0.9182\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 34s 574us/step - loss: 0.0902 - accuracy: 0.9658 - val_loss: 0.3141 - val_accuracy: 0.9169\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 35s 578us/step - loss: 0.0920 - accuracy: 0.9650 - val_loss: 0.3096 - val_accuracy: 0.9152\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 35s 577us/step - loss: 0.0913 - accuracy: 0.9652 - val_loss: 0.3057 - val_accuracy: 0.9187\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 35s 575us/step - loss: 0.0906 - accuracy: 0.9653 - val_loss: 0.3133 - val_accuracy: 0.9165\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 35s 577us/step - loss: 0.0919 - accuracy: 0.9638 - val_loss: 0.3038 - val_accuracy: 0.9184\n",
            "Large CNN Error for fashion_mnist: 8.16%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQtGF3cCcBHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}